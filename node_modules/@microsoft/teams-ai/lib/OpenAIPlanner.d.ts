/**
 * @module teams-ai
 */
/**
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
import { Planner, Plan } from './Planner';
import { TurnState } from './TurnState';
import { DefaultTurnState } from './DefaultTurnStateManager';
import { TurnContext } from 'botbuilder';
import { OpenAIClient } from './OpenAIClients';
import { ConfiguredAIOptions } from './AI';
import { PromptTemplate } from './Prompts';
/**
 * Options for the OpenAI based planner.
 */
export interface OpenAIPlannerOptions {
    /**
     * OpenAI API key.
     */
    apiKey: string;
    /**
     * Optional. OpenAI organization.
     */
    organization?: string;
    /**
     * Optional. OpenAI endpoint.
     */
    endpoint?: string;
    /**
     * The default model to use.
     * @remarks
     * Prompts can override this model.
     */
    defaultModel: string;
    /**
     * Optional. A flag indicating if the planner should only say one thing per turn.
     * @remarks
     * The planner will attempt to combine multiple SAY commands into a single SAY command when true.
     * Defaults to false.
     */
    oneSayPerTurn?: boolean;
    /**
     * Optional. A flag indicating if the planner should use the 'system' role when calling OpenAI's
     * chatCompletion API.
     * @remarks
     * The planner current uses the 'user' role by default as this tends to generate more reliable
     * instruction following. Defaults to false.
     */
    useSystemMessage?: boolean;
    /**
     * Optional. A flag indicating if the planner should log requests to the console.
     * @remarks
     * Both the prompt text and the completion response will be logged to the console. For
     * chatCompletion calls the outgoing messages array will also be logged.
     * Defaults to false.
     */
    logRequests?: boolean;
}
/**
 * A planner that uses OpenAI's textCompletion and chatCompletion API's to generate plans.
 * @remarks
 * This planner can be configured to use different models for different prompts. The prompts model
 * will determine which API is used to generate the plan. Any model that starts with 'gpt-' will
 * use the chatCompletion API, otherwise the textCompletion API will be used.
 * @template TState Optional. Type of the applications turn state.
 * @template TOptions Optional. Type of the planner options.
 */
export declare class OpenAIPlanner<TState extends TurnState = DefaultTurnState, TOptions extends OpenAIPlannerOptions = OpenAIPlannerOptions> implements Planner<TState> {
    private readonly _options;
    private readonly _client;
    /**
     * Creates a new instance of the OpenAI based planner.
     * @param options Options for the OpenAI based planner.
     */
    constructor(options: TOptions);
    /**
     * Returns the configured options for the planner.
     */
    get options(): TOptions;
    /**
     * Completes a prompt without returning a plan.
     * @param context Context for the current turn of conversation.
     * @param state Application state for the current turn of conversation.
     * @param prompt Prompt to complete.
     * @param options Configuration options for the AI system.
     * @returns The response from the prompt. Can return undefined to indicate the prompt was rate limited.
     */
    completePrompt(context: TurnContext, state: TState, prompt: PromptTemplate, options: ConfiguredAIOptions<TState>): Promise<string>;
    /**
     * Completes a prompt and generates a plan for the AI system to execute.
     * @param context Context for the current turn of conversation.
     * @param state Application state for the current turn of conversation.
     * @param prompt Prompt to complete.
     * @param options Configuration options for the AI system.
     * @returns The plan that was generated.
     */
    generatePlan(context: TurnContext, state: TState, prompt: PromptTemplate, options: ConfiguredAIOptions<TState>): Promise<Plan>;
    /**
     * @private
     */
    protected createClient(options: TOptions): OpenAIClient;
    /**
     * @private
     */
    private getModel;
    /**
     * @private
     */
    private createChatCompletionRequest;
    /**
     * @private
     */
    private createCompletionRequest;
    /**
     * @private
     */
    private patchStopSequences;
    /**
     * @private
     */
    private createChatCompletion;
    /**
     * @private
     */
    private createCompletion;
}
//# sourceMappingURL=OpenAIPlanner.d.ts.map